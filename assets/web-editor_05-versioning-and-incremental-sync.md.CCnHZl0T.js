import{f as r,D as s,c as p,o as n,k as l,a4 as i,H as t,a as e}from"./chunks/framework.BAs4fWuZ.js";const k=JSON.parse('{"title":"Web 编辑器如何增量提交与版本管理：op log、快照与可回放系统","description":"","frontmatter":{"title":"Web 编辑器如何增量提交与版本管理：op log、快照与可回放系统","date":"2026-01-22T00:00:00.000Z","categories":"study","tags":["web-editor","collaboration","versioning","snapshot","oplog","reliability"]},"headers":[],"relativePath":"web-editor/05-versioning-and-incremental-sync.md","filePath":"web-editor/05-versioning-and-incremental-sync.md","lastUpdated":1769026429000}'),h={name:"web-editor/05-versioning-and-incremental-sync.md"};function d(c,a,u,m,b,g){const o=s("InkMermaidBlock");return n(),p("div",null,[a[0]||(a[0]=l("div",{class:"alert read-stats",role:"note"},[l("span",{class:"read-stats__icon","aria-hidden":"true"},"🔖"),l("span",{class:"read-stats__text"},[e("本文约 "),l("b",null,"3482"),e(" 字，阅读预计耗时 "),l("b",null,"9"),e(" 分钟。")])],-1)),a[1]||(a[1]=l("div",{class:"alert ai-disclosure",role:"note"},[l("span",{class:"ai-disclosure__icon","aria-hidden":"true"},"ⓘ"),l("span",{class:"ai-disclosure__text"},"AI 辅助写作声明：本文由博主构思逻辑，AI 辅助润色，双方共同校对。")],-1)),a[2]||(a[2]=i('<p>协同/版本管理这块，最容易出现一种错觉：demo 跑通了就以为“做完了”。上线后才开始遇到：重连丢操作、回放卡死、偶现错位、以及用户问你“我刚刚那段文字去哪了”。</p><h2 id="问题-编辑器的-增量提交-到底提交的是什么" tabindex="-1">问题：编辑器的“增量提交”到底提交的是什么？ <a class="header-anchor" href="#问题-编辑器的-增量提交-到底提交的是什么" aria-label="Permalink to &quot;问题：编辑器的“增量提交”到底提交的是什么？&quot;">​</a></h2><p>先明确一个很现实的问题：你提交的是“文本变化”，还是“文档变化”？</p><ul><li>如果你提交整份 HTML：数据大、不可控、回放难、diff 难</li><li>如果你提交整份 JSON 文档：同样大，且富文本结构变更频繁</li><li>如果你提交操作（ops/steps/patches）：数据小，可回放，但要解决版本对齐、压缩、校验</li></ul><p>所以工程上更常见的落点是：<strong>提交操作日志（op log），配合快照（snapshot）与版本管理（versioning）</strong>。</p><p>这套组合拳解决三个问题：</p><ol><li>网络层：怎么把变更传出去（batch、重试、幂等）</li><li>一致性层：怎么知道谁落后了、缺哪段日志（版本向量/修订号）</li><li>可运维层：怎么排障（确定性回放、对账校验）</li></ol><h2 id="分析-版本管理的三种常见模型-横向对比" tabindex="-1">分析：版本管理的三种常见模型（横向对比） <a class="header-anchor" href="#分析-版本管理的三种常见模型-横向对比" aria-label="Permalink to &quot;分析：版本管理的三种常见模型（横向对比）&quot;">​</a></h2><table tabindex="0"><thead><tr><th>模型</th><th>形态</th><th>解决的问题</th><th>适用场景</th><th>常见坑</th></tr></thead><tbody><tr><td>单调 revision（rev）</td><td>服务端权威递增整数</td><td>顺序、回放、补洞</td><td>OT/中心化协同</td><td>离线合并弱、跨房间/分片需要额外设计</td></tr><tr><td>Lamport clock</td><td>(counter, clientId)</td><td>部分因果顺序</td><td>分布式事件排序</td><td>只能给出“先后”，难表达“并发集合”</td></tr><tr><td>Version vector（向量时钟）</td><td>client -&gt; counter map</td><td>因果关系与缺失集合</td><td>CRDT/离线协同</td><td>向量膨胀，需要压缩与成员管理</td></tr></tbody></table><p>四舍五入：如果你的协同是“服务端权威广播”，rev 是最直接的；如果你需要离线编辑 + 多端合并，向量时钟更靠谱。</p><h2 id="解决方案-op-log-snapshot-校验-纵向深入两层" tabindex="-1">解决方案：op log + snapshot + 校验（纵向深入两层） <a class="header-anchor" href="#解决方案-op-log-snapshot-校验-纵向深入两层" aria-label="Permalink to &quot;解决方案：op log + snapshot + 校验（纵向深入两层）&quot;">​</a></h2><p>我习惯把系统拆两层：</p><ul><li>数据层：操作是事实（op log），快照是锚点（snapshot）</li><li>系统层：网络重试、幂等、对账、回放，让系统可运维</li></ul><h3 id="增量提交架构图-源文件-assets-diagrams-versioning-oplog-snapshot-mmd" tabindex="-1">增量提交架构图（源文件：<code>../assets/diagrams/versioning-oplog-snapshot.mmd</code>） <a class="header-anchor" href="#增量提交架构图-源文件-assets-diagrams-versioning-oplog-snapshot-mmd" aria-label="Permalink to &quot;增量提交架构图（源文件：`../assets/diagrams/versioning-oplog-snapshot.mmd`）&quot;">​</a></h3>',14)),t(o,{codeBase64:"Zmxvd2NoYXJ0IExSCiAgc3ViZ3JhcGggQ2xpZW50CiAgICBFW0VkaXRvcl0KICAgIEJbQmF0Y2hlcjxici8+KGRlYm91bmNlL21lcmdlKV0KICAgIExbTG9jYWwgTG9nXQogICAgRSAtLT4gQiAtLT4gTAogIGVuZAoKICBzdWJncmFwaCBTZXJ2ZXIKICAgIFZbVmFsaWRhdG9yXQogICAgUFtQZXJzaXN0IExvZ10KICAgIFNbU25hcHNob3R0ZXJdCiAgICBWIC0tPiBQIC0tPiBTCiAgZW5kCgogIENsaWVudCAtLT58cHVzaCBvcHMgKyB2ZXJzaW9ufCBWCiAgU2VydmVyIC0tPnxicm9hZGNhc3Qgb3BzfCBDbGllbnQKICBTIC0tPnxzZXJ2ZSBzbmFwc2hvdCArIHRhaWwgb3BzfCBDbGllbnQK"}),a[3]||(a[3]=i('<h3 id="版本管理的-几何直觉-rev、opid、向量时钟各解决一类痛点" tabindex="-1">版本管理的“几何直觉”：rev、opId、向量时钟各解决一类痛点 <a class="header-anchor" href="#版本管理的-几何直觉-rev、opid、向量时钟各解决一类痛点" aria-label="Permalink to &quot;版本管理的“几何直觉”：rev、opId、向量时钟各解决一类痛点&quot;">​</a></h3><p>我更喜欢把版本管理类比成 Git（但别过度类比）：</p><ul><li>op log 像 commit 序列：每一条操作是一个可回放的“事实”</li><li>snapshot 像 tag/checkout 点：把历史压平到一个锚点</li><li>校验像 hash：你得能证明“大家看的确实是同一份内容”</li></ul><p>下面用符号把三个常见模型讲清楚。</p><h4 id="_1-单调-revision-最容易落地的中心化版本模型" tabindex="-1">1) 单调 revision：最容易落地的中心化版本模型 <a class="header-anchor" href="#_1-单调-revision-最容易落地的中心化版本模型" aria-label="Permalink to &quot;1) 单调 revision：最容易落地的中心化版本模型&quot;">​</a></h4><p>设服务端维护一个单调递增版本号 revₛ。客户端记录自己已确认的 rev_c。</p><p>当客户端重连时，“缺哪段日志”其实就是一个区间：</p><ul><li>missing = (rev_c, revₛ]</li></ul><p>这句话写出来，很多边界条件就自然出现：</p><ul><li>rev_c 可能大于 revₛ（客户端缓存坏了/跨房间提交）：要拒绝并下发 snapshot</li><li>missing 可能很长：要下发 snapshot + tail ops，而不是全量 oplog</li></ul><h4 id="_2-幂等提交-opid-是网络重试的-身份证" tabindex="-1">2) 幂等提交：opId 是网络重试的“身份证” <a class="header-anchor" href="#_2-幂等提交-opid-是网络重试的-身份证" aria-label="Permalink to &quot;2) 幂等提交：opId 是网络重试的“身份证”&quot;">​</a></h4><p>网络层一定会重试，重试就一定会重复提交。因此你需要让“提交”变成幂等操作。</p><p>最朴素的做法：每个 op 带一个全局唯一 opId（clientId + localCounter 就够用），服务端维护 seen(opId)。</p><p>规则很简单：</p><ul><li>若 opId 已见过：忽略（不改变 rev，不写入 log）</li><li>若 opId 未见过：写入 log，revₛ := revₛ + 1</li></ul><p>它的意义不是“去重很酷”，而是把“网络层的不确定性”隔离在最外层，避免污染协同语义。</p><h4 id="_3-向量时钟-把-并发集合-讲明白" tabindex="-1">3) 向量时钟：把“并发集合”讲明白 <a class="header-anchor" href="#_3-向量时钟-把-并发集合-讲明白" aria-label="Permalink to &quot;3) 向量时钟：把“并发集合”讲明白&quot;">​</a></h4><p>向量时钟可以看成一个映射 VC：client → counter。</p><p>关键操作只有两个：</p><ul><li>自增：VCᵢ[i] := VCᵢ[i] + 1（本客户端产生新操作）</li><li>合并：Merge(VCᵃ, VCᵇ)[k] := max(VCᵃ[k], VCᵇ[k])</li></ul><p>支配关系（dominates）用来判断“我是否已经看到你的一切”：</p><ul><li>VCᵃ ⪰ VCᵇ 当且仅当 ∀k, VCᵃ[k] ≥ VCᵇ[k]</li></ul><p>它解决的是：离线编辑与多端合并时，单调 rev 说不清“谁缺谁哪些操作”，向量时钟能说清。</p><h3 id="快照-tail-ops-把回放从-无限长-变成-有窗口" tabindex="-1">快照 + tail ops：把回放从“无限长”变成“有窗口” <a class="header-anchor" href="#快照-tail-ops-把回放从-无限长-变成-有窗口" aria-label="Permalink to &quot;快照 + tail ops：把回放从“无限长”变成“有窗口”&quot;">​</a></h3><p>快照 snapshot 是一个锚点，至少包含：</p><ul><li>snapshot.rev：这份状态对应的版本号</li><li>snapshot.doc：完整文档状态（或模型状态）</li><li>snapshot.checksum：用于对账的摘要（hash(doc)，算法不重要，稳定与抗碰撞更重要）</li></ul><p>当服务端下发状态时，尽量下发：</p><ul><li>snapshot（锚点）</li><li>tail ops（从 snapshot.rev 之后的一小段增量）</li></ul><p>客户端回放其实就是一个可复述的式子：</p><ul><li>doc₀ = snapshot.doc</li><li>docₙ = Apply(docₙ₋₁, opₙ)</li></ul><p>只要 Apply 是确定的（同输入同输出），回放就能成为排障底牌：你可以在任何机器上重放同一段 tail ops，得到同一个 checksum。</p><h3 id="重连与补洞流程图-把-掉线-当成常态设计" tabindex="-1">重连与补洞流程图：把“掉线”当成常态设计 <a class="header-anchor" href="#重连与补洞流程图-把-掉线-当成常态设计" aria-label="Permalink to &quot;重连与补洞流程图：把“掉线”当成常态设计&quot;">​</a></h3>',32)),t(o,{codeBase64:"Zmxvd2NoYXJ0IFRCCiAgRENb5pat57q/L+WIh+WQjuWPsF0gLS0+IFJDW+mHjei/nl0KICBSQyAtLT4gSFNb5o+h5omLOiDkuIrmiqUgcmV2IOaIliB2ZWN0b3IgY2xvY2tdCiAgSFMgLS0+IERJRkZb5pyN5Yqh56uv6K6h566X57y65aSx5Yy66Ze0L+e8uuWksembhuWQiF0KICBESUZGIC0tPnzov4fplb8v5LiN5Y+v5L+hfCBTTkFQW+S4i+WPkSBzbmFwc2hvdF0KICBESUZGIC0tPnzlj6/ooaXmtJ58IFRBSUxb5LiL5Y+RIHRhaWwgb3BzXQogIFNOQVAgLS0+IEFQUExZW+WuouaIt+err+W6lOeUqCBzbmFwc2hvdF0KICBUQUlMIC0tPiBSRVBMQVlb5a6i5oi356uv5Zue5pS+IHRhaWwgb3BzXQogIEFQUExZIC0tPiBSRVBMQVkKICBSRVBMQVkgLS0+IENLW+Wvuei0pjogY2hlY2tzdW0g5q+U5a+5XQogIENLIC0tPnzkuIDoh7R8IE9LW+i/m+WFpeWunuaXtuWNj+WQjF0KICBDSyAtLT585LiN5LiA6Ie0fCBGSVhb5by65Yi25LiL5Y+RIHNuYXBzaG90PGJyLz7miJbop6blj5Hlm57mlL7or4rmlq1dCg=="}),a[4]||(a[4]=i('<h2 id="工程实践-增量提交的-坑点清单" tabindex="-1">工程实践：增量提交的“坑点清单” <a class="header-anchor" href="#工程实践-增量提交的-坑点清单" aria-label="Permalink to &quot;工程实践：增量提交的“坑点清单”&quot;">​</a></h2><h3 id="_1-提交边界-ime、粘贴与批量操作" tabindex="-1">1) 提交边界：IME、粘贴与批量操作 <a class="header-anchor" href="#_1-提交边界-ime、粘贴与批量操作" aria-label="Permalink to &quot;1) 提交边界：IME、粘贴与批量操作&quot;">​</a></h3><ul><li>IME（composition）期间不要拆碎成一堆 op；否则回放会出现“看起来一样但选区乱了”的诡异问题</li><li>粘贴/格式化通常是批量变更：应该合并成一个 transaction/op batch</li><li>大操作需要“分帧提交”：避免主线程一次性处理过多变更导致卡顿</li></ul><h3 id="_2-压缩-compaction-日志一定会膨胀" tabindex="-1">2) 压缩（compaction）：日志一定会膨胀 <a class="header-anchor" href="#_2-压缩-compaction-日志一定会膨胀" aria-label="Permalink to &quot;2) 压缩（compaction）：日志一定会膨胀&quot;">​</a></h3><ul><li>相邻插入可合并（pos 连续、来源同一批次）</li><li>insert + delete 抵消可简化</li><li>到某个阈值做 snapshot，把 tail 控制在可回放窗口</li></ul><h3 id="_3-对账-checksum-不要迷信-最终一致" tabindex="-1">3) 对账（checksum）：不要迷信“最终一致” <a class="header-anchor" href="#_3-对账-checksum-不要迷信-最终一致" aria-label="Permalink to &quot;3) 对账（checksum）：不要迷信“最终一致”&quot;">​</a></h3><p>一致性不是一句口号，它要可证明：</p><ul><li>客户端定期上报 checksum（针对 snapshot rev）</li><li>服务端计算同 rev 的 checksum 做对账</li><li>不一致就触发回放与修复（下发 snapshot）</li></ul><p>这里有一个容易被忽略的工程细节：checksum 不一致时，你不要急着“直接覆盖客户端”。</p><p>更稳的处理流程是：</p><ul><li>先冻结客户端继续提交（否则你会在错误状态上继续累积）</li><li>拉取服务端的 snapshot + tail ops，与本地 oplog 做一次对比回放</li><li>如果能定位到某一段 tail ops 导致分歧：记录并上报（这是排障证据）</li><li>最后再选择修复策略：覆盖、合并、或提示用户冲突（取决于产品规则）</li></ul><p>比喻一下：对账像银行对账单。对不上不是立刻把你的余额改成银行的，而是先找出哪一笔流水不一致，然后再决定怎么处理。</p><h3 id="_4-背压-backpressure-别让网络把编辑器拖死" tabindex="-1">4) 背压（backpressure）：别让网络把编辑器拖死 <a class="header-anchor" href="#_4-背压-backpressure-别让网络把编辑器拖死" aria-label="Permalink to &quot;4) 背压（backpressure）：别让网络把编辑器拖死&quot;">​</a></h3><p>增量提交最容易忽略的一点是：编辑器的输入是连续的，但网络与服务端处理能力是离散的。</p><p>你需要一个“背压策略”，否则会出现两种极端：</p><ul><li>客户端疯狂堆 op：内存增长、重连补洞变成灾难</li><li>客户端强行等确认：输入延迟上升，用户感觉“打字黏”</li></ul><p>工程上更稳的做法是分三层缓冲：</p><ul><li>UI 层：输入即时生效（本地先 apply）</li><li>传输层：op 批量发送（batch）+ 限速（rate limit）+ 合并（merge）</li><li>存储层：服务端确认后再推进“已确认水位线”（confirmed rev / confirmed VC）</li></ul><p>比喻一下：这就像快递揽收。用户把包裹交给你（本地生效），你可以先放到仓库（本地 log），但你不能让仓库无限堆，也不能要求每个包裹都必须当天送达才允许继续揽收。</p><h3 id="_5-快照策略-什么时候打点、打多密" tabindex="-1">5) 快照策略：什么时候打点、打多密？ <a class="header-anchor" href="#_5-快照策略-什么时候打点、打多密" aria-label="Permalink to &quot;5) 快照策略：什么时候打点、打多密？&quot;">​</a></h3><p>快照不是越多越好。快照太密会带来：</p><ul><li>服务端写放大（存储与 IO 压力）</li><li>生成快照的 CPU 成本</li></ul><p>快照太稀会带来：</p><ul><li>重连 tail ops 太长，回放耗时不可控</li><li>线上排障难度上升（缺少稳定锚点）</li></ul><p>比较常见的折中策略是“阈值触发”：</p><ul><li>当 tail ops 数量超过 N，或 tail 字节超过 M，触发一次 snapshot</li><li>或者按时间窗口定期 snapshot（例如每 30s / 2min），配合阈值兜底</li></ul><p>四舍五入：快照是把系统从“可用”推到“可运维”的关键设施，建议在早期就设计好，而不是等日志膨胀后再补。</p><h2 id="关键前提-apply-必须确定-否则一切对账都只是自欺欺人" tabindex="-1">关键前提：Apply 必须确定，否则一切对账都只是自欺欺人 <a class="header-anchor" href="#关键前提-apply-必须确定-否则一切对账都只是自欺欺人" aria-label="Permalink to &quot;关键前提：Apply 必须确定，否则一切对账都只是自欺欺人&quot;">​</a></h2><p>上面很多设计（checksum、回放、tail 窗口）都隐含了一个前提：同一段 snapshot + 同一段 tail ops，在任何机器上回放都必须得到同一份结果。否则你会遇到一种最糟糕的情况：系统能同步，但永远对不上账。</p><p>导致非确定性的常见来源包括：</p><ul><li>依赖当前时间、随机数、或浏览器环境差异（例如不同字体测量导致布局回写到模型）</li><li>插件在 apply 阶段读取外部状态（网络返回、localStorage、全局单例）</li><li>normalize 规则不稳定（同一份输入在不同顺序下修复出不同结果）</li></ul><p>工程上更稳的约束是：模型层的 Apply 与 Normalize 必须是纯函数风格，外部依赖要么被显式写入 op payload，要么只允许在渲染层产生影响（不回写模型）。</p><h2 id="回放诊断-把-偶现-压缩成可复制的最小证据" tabindex="-1">回放诊断：把“偶现”压缩成可复制的最小证据 <a class="header-anchor" href="#回放诊断-把-偶现-压缩成可复制的最小证据" aria-label="Permalink to &quot;回放诊断：把“偶现”压缩成可复制的最小证据&quot;">​</a></h2><p>当对账失败时，真正值钱的不是“重新下发快照把用户救回来”，而是把分歧变成一份可复制的证据。建议你在系统里预留一个最小诊断包：</p><ul><li>snapshot（含 rev 与 checksum）</li><li>tail ops（含每条 op 的 id、来源、时间戳/逻辑时间、摘要）</li><li>关键环境（浏览器版本、输入法状态、核心与插件版本矩阵）</li></ul><p>这份诊断包的目标不是“把所有信息都打出来”，而是让你能在本地一键重放，并稳定复现分歧发生的那一条 op。只要能稳定复现，修复就会从玄学变成工程。</p><h2 id="确认水位线-本地先应用不等于-已经安全" tabindex="-1">确认水位线：本地先应用不等于“已经安全” <a class="header-anchor" href="#确认水位线-本地先应用不等于-已经安全" aria-label="Permalink to &quot;确认水位线：本地先应用不等于“已经安全”&quot;">​</a></h2><p>增量提交系统里有两个很容易混淆的概念：</p><ul><li>本地已应用：用户看到的内容已经更新（体验优先）</li><li>服务端已确认：这段变更已经进入“可回放事实”（安全与一致性）</li></ul><p>如果你不区分这两者，就会遇到一类非常经典的线上事故：用户输入了内容，看起来没问题；但网络抖一下、服务端拒绝一批 ops、或者发生重连补洞后，这段内容悄悄消失或被回滚，用户只会觉得“你吃字了”。</p><p>更稳的做法是维护一个“确认水位线”：</p><ul><li>对中心化 rev：confirmedRev ≤ localRev</li><li>对向量时钟：confirmedVC ⪯ localVC（逐分量不大于）</li></ul><p>并在 UI 层做最小可见化：</p><ul><li>未确认的变更可以有轻量提示（例如状态栏“正在同步…”）</li><li>当出现拒绝/回滚时，要能把差异定位到具体 op（而不是整份文档闪回）</li></ul><p>这背后其实是一条系统设计原则：本地乐观更新可以提升体验，但必须用“确认水位线 + 回放证据”把一致性与安全补回来。</p><h2 id="日志压缩的边界-哪些能合并-哪些不能碰" tabindex="-1">日志压缩的边界：哪些能合并，哪些不能碰 <a class="header-anchor" href="#日志压缩的边界-哪些能合并-哪些不能碰" aria-label="Permalink to &quot;日志压缩的边界：哪些能合并，哪些不能碰&quot;">​</a></h2><p>很多人讲 compaction 时会说“相邻插入合并、insert+delete 抵消”，听起来都对，但真正落地时最容易踩的坑是：你合并了本不该合并的东西，结果回放仍然一致，但用户语义变了（撤销粒度变了、协同里光标跳了、选区映射不再可解释）。</p><p>更稳的原则是先写清楚“合并边界”：</p><ul><li><strong>输入边界</strong>：IME composition 期间的中间态不要跨边界合并到最终上屏之外</li><li><strong>事务边界</strong>：不同 transaction 的 op 不要随意跨事务合并，否则你会把产品语义改坏</li><li><strong>结构边界</strong>：跨节点/跨块的变更不要用纯文本规则粗暴合并，否则 normalize 的结果可能不同</li></ul><p>一种更工程化的做法是给每批 op 打上 batchId，并把 batchId 作为合并条件之一：同一 batchId 的相邻 op 才允许合并。这样你至少能把合并范围限定在“人类一次操作”的窗口里，而不是把整段历史揉成一坨。</p><p>四舍五入：压缩不是为了让日志更漂亮，而是为了把回放窗口控制在可用范围内，同时不破坏你对“用户一次操作”的语义承诺。</p><h2 id="校验的边界-checksum-不是安全机制-但它是工程底线" tabindex="-1">校验的边界：checksum 不是安全机制，但它是工程底线 <a class="header-anchor" href="#校验的边界-checksum-不是安全机制-但它是工程底线" aria-label="Permalink to &quot;校验的边界：checksum 不是安全机制，但它是工程底线&quot;">​</a></h2><p>很多人听到 checksum 会下意识联想到“安全”，但在协同系统里 checksum 的第一目标不是防攻击，而是防分歧：你要快速回答“我们是不是在同一个世界里”。因此你更关心的是稳定性与可重复性，而不是密码学意义上的完美。</p><p>一个更可操作的 checklist 是：</p><ul><li>校验输入必须明确：按同一种序列化方式 hash（不要一边 hash JSON，一边 hash HTML）</li><li>校验粒度必须可控：既要能对 snapshot 整体校验，也要能对某个段落/某个 block 做局部校验</li><li>校验失败必须可止血：允许快速进入“冻结提交 → 下发快照 → 记录诊断包”的模式</li></ul><p>你可以把它写成非常朴素的形式：checksum = H(Serialize(doc, rev))。这里真正重要的不是 H 是什么，而是 Serialize 的确定性：字段顺序、默认值、浮点数格式、以及是否包含临时字段，都必须被明确约束。否则你会遇到一种最让人绝望的情况：数据其实一致，但 checksum 永远对不上。</p><h2 id="参考与引用" tabindex="-1">参考与引用 <a class="header-anchor" href="#参考与引用" aria-label="Permalink to &quot;参考与引用&quot;">​</a></h2><ol><li>ProseMirror collab 示例（op 级同步思路）：<a href="https://prosemirror.net/examples/collab/" target="_blank" rel="noreferrer">https://prosemirror.net/examples/collab/</a> （Bib: <code>prosemirror_collab</code>）</li><li>Yjs 基础与同步协议：<a href="https://docs.yjs.dev/" target="_blank" rel="noreferrer">https://docs.yjs.dev/</a> （Bib: <code>yjs_docs</code>）</li><li>Automerge（CRDT）文档：<a href="https://automerge.org/" target="_blank" rel="noreferrer">https://automerge.org/</a> （Bib: <code>automerge_docs</code>）</li><li>W3C WebSocket API（传输层基建）：<a href="https://websockets.spec.whatwg.org/" target="_blank" rel="noreferrer">https://websockets.spec.whatwg.org/</a> （Bib: <code>whatwg_websocket</code>）</li></ol>',58))])}const _=r(h,[["render",d]]);export{k as __pageData,_ as default};
