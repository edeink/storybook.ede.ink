import{f as o,D as d,c as p,o as s,k as i,a4 as a,H as t,a as r}from"./chunks/framework.BAs4fWuZ.js";const P=JSON.parse('{"title":"Web 编辑器的数据怎么存：Rope、Piece Table、区间树与红黑树","description":"","frontmatter":{"title":"Web 编辑器的数据怎么存：Rope、Piece Table、区间树与红黑树","date":"2026-01-21T00:00:00.000Z","categories":"study","tags":["web-editor","data-structure","rope","piece-table","interval-tree","performance"]},"headers":[],"relativePath":"web-editor/04-doc-storage-and-indexes.md","filePath":"web-editor/04-doc-storage-and-indexes.md","lastUpdated":1769026429000}'),n={name:"web-editor/04-doc-storage-and-indexes.md"};function c(b,e,u,h,m,g){const l=d("InkMermaidBlock");return s(),p("div",null,[e[0]||(e[0]=i("div",{class:"alert read-stats",role:"note"},[i("span",{class:"read-stats__icon","aria-hidden":"true"},"🔖"),i("span",{class:"read-stats__text"},[r("本文约 "),i("b",null,"2723"),r(" 字，阅读预计耗时 "),i("b",null,"7"),r(" 分钟。")])],-1)),e[1]||(e[1]=i("div",{class:"alert ai-disclosure",role:"note"},[i("span",{class:"ai-disclosure__icon","aria-hidden":"true"},"ⓘ"),i("span",{class:"ai-disclosure__text"},"AI 辅助写作声明：本文由博主构思逻辑，AI 辅助润色，双方共同校对。")],-1)),e[2]||(e[2]=a('<p>编辑器的数据结构，属于那种“平时看不见，一出事就要命”的底层活：性能抖一下，用户第一反应是“卡”；数据错一下，用户第二反应是“你赔我稿子”。</p><h2 id="问题-编辑器的文档到底怎么存-才能既快又稳" tabindex="-1">问题：编辑器的文档到底怎么存，才能既快又稳？ <a class="header-anchor" href="#问题-编辑器的文档到底怎么存-才能既快又稳" aria-label="Permalink to &quot;问题：编辑器的文档到底怎么存，才能既快又稳？&quot;">​</a></h2><p>直觉做法是：用一个大字符串存全文，插入就 <code>slice + concat</code>，删除也一样。</p><p>然后你会发现：</p><ul><li>每次插入一个字符都在复制 O(n) 的字符串，长文档直接原地升天</li><li>你想支持 undo/redo，就要保存一堆大字符串快照，内存爆炸</li><li>你想做协同，要记录操作日志（op log），但每次回放如果都靠全量字符串拼接，回放性能会崩</li><li>你想做高亮、批注、标记范围（ranges/decorations），查询“某个位置命中了哪些范围”会变成线性扫，越用越慢</li></ul><p>究其根本：编辑器的数据不是“文本”，而是“文本 + 结构 + 元信息（range/decoration）”。你需要两类东西：</p><ol><li>文本存储结构：让插入/删除/切片/回放更便宜</li><li>区间索引结构：让范围查询/命中判断更便宜</li></ol><p>这篇文章讲两条主线：</p><ul><li>文本：Rope / Piece Table / Gap Buffer 的取舍</li><li>范围：Interval Tree（很多实现会落在红黑树上）在编辑器里怎么发挥作用</li></ul><h2 id="分析-三种文本存储结构-横向对比" tabindex="-1">分析：三种文本存储结构（横向对比） <a class="header-anchor" href="#分析-三种文本存储结构-横向对比" aria-label="Permalink to &quot;分析：三种文本存储结构（横向对比）&quot;">​</a></h2><table tabindex="0"><thead><tr><th>结构</th><th>核心思想</th><th>插入/删除成本</th><th>适用场景</th><th>常见坑</th></tr></thead><tbody><tr><td>Gap Buffer</td><td>光标附近留一个“空洞”</td><td>光标附近快，远距离慢</td><td>纯文本、单光标编辑</td><td>多光标/大范围编辑时移动 gap 代价大</td></tr><tr><td>Piece Table</td><td>原文不动，新插入放增量 buffer，用 piece 指向片段</td><td>操作成本靠 split/merge</td><td>编辑器主流思路之一</td><td>piece 碎片化，需要合并/压缩</td></tr><tr><td>Rope</td><td>平衡树存片段，支持高效拼接/切分</td><td>依赖树平衡</td><td>长文本、高并发修改</td><td>常数项大，实现复杂，调试困难</td></tr></tbody></table><p>四舍五入：如果你要做“富文本编辑器”，最终通常会走向 <strong>Piece Table 或 Rope</strong>（或者“树结构的 Piece Table”）。</p><h2 id="解决方案-1-piece-table-编辑器的工程甜点" tabindex="-1">解决方案 1：Piece Table（编辑器的工程甜点） <a class="header-anchor" href="#解决方案-1-piece-table-编辑器的工程甜点" aria-label="Permalink to &quot;解决方案 1：Piece Table（编辑器的工程甜点）&quot;">​</a></h2><p>Piece Table 的关键点是：<strong>原始文本不改动</strong>，新插入的文本追加到 addBuffer，文档内容由一张“片段表”拼出来。</p><h3 id="piece-table-数据流图-源文件-assets-diagrams-doc-storage-piece-table-mmd" tabindex="-1">Piece Table 数据流图（源文件：<code>../assets/diagrams/doc-storage-piece-table.mmd</code>） <a class="header-anchor" href="#piece-table-数据流图-源文件-assets-diagrams-doc-storage-piece-table-mmd" aria-label="Permalink to &quot;Piece Table 数据流图（源文件：`../assets/diagrams/doc-storage-piece-table.mmd`）&quot;">​</a></h3>',15)),t(l,{codeBase64:"Zmxvd2NoYXJ0IFRCCiAgc3ViZ3JhcGggQnVmZmVycwogICAgT0JbT3JpZ2luYWwgQnVmZmVyPGJyLz5pbW11dGFibGVdCiAgICBBQltBZGQgQnVmZmVyPGJyLz5hcHBlbmQtb25seV0KICBlbmQKCiAgc3ViZ3JhcGggUGllY2VzWyJQaWVjZSBUYWJsZSAob3JkZXJlZCkiXQogICAgUDFbUGllY2U6IE9CIG9mZnNldC4ubGVuXQogICAgUDJbUGllY2U6IEFCIG9mZnNldC4ubGVuXQogICAgUDNbUGllY2U6IE9CIG9mZnNldC4ubGVuXQogIGVuZAoKICBPQiAtLT4gUDEKICBBQiAtLT4gUDIKICBPQiAtLT4gUDMKICBQaWVjZXMgLS0+IFZbTWF0ZXJpYWxpemUgLyBSZW5kZXJdCg=="}),e[3]||(e[3]=a('<h3 id="piece-table-的-几何感-你在维护一张目录-而不是在改正文" tabindex="-1">Piece Table 的“几何感”：你在维护一张目录，而不是在改正文 <a class="header-anchor" href="#piece-table-的-几何感-你在维护一张目录-而不是在改正文" aria-label="Permalink to &quot;Piece Table 的“几何感”：你在维护一张目录，而不是在改正文&quot;">​</a></h3><p>把 Piece Table 想成三件东西：</p><ul><li>Original Buffer：档案馆里的原始稿纸，只读不改</li><li>Add Buffer：桌上的便签本，只追加不回头</li><li>Pieces：目录索引，按顺序指向“从哪一张纸抄哪一段”</li></ul><p>因此一次编辑不是“修改正文”，而是“修改目录”。这也是它能快的根本原因：目录变了，正文不需要整段复制。</p><p>为了能把算法讲清楚，我们用更抽象的记号描述一个 piece：</p><ul><li>piece = (buf, off, len)</li><li>buf ∈ {OB, AB} 分别指向 Original/Add</li><li>文档内容 = 依次拼接所有 piece 指向的片段</li></ul><h4 id="插入算法-自然语言版" tabindex="-1">插入算法（自然语言版） <a class="header-anchor" href="#插入算法-自然语言版" aria-label="Permalink to &quot;插入算法（自然语言版）&quot;">​</a></h4><p>输入：全局位置 p，插入文本 x。</p><ol><li>把 x 追加到 Add Buffer 末尾，得到它在 Add Buffer 中的区间 [a, a+|x|)</li><li>在 Pieces 上定位全局位置 p 落在哪个 piece 里（这一步决定了你能不能做到快）</li><li>把命中的 piece 在 p 处切成 left / right 两段</li><li>把 insertPiece=(AB, a, |x|) 插到 left 与 right 中间</li></ol><p>这里最“数学”的一句话其实就是切分：</p><ul><li>原 piece： (buf, off, len)</li><li>切分点 k（k 是该 piece 内部偏移，0≤k≤len）</li><li>left = (buf, off, k)，right = (buf, off+k, len-k)</li></ul><p>插入的复杂度主要来自两件事：</p><ul><li>定位：找到 p（如果线性扫 pieces，就是 O(#pieces)）</li><li>结构变更：切分与插入（通常是 O(1) 级别的结构操作，但依赖你 pieces 的容器）</li></ul><h4 id="删除算法-自然语言版" tabindex="-1">删除算法（自然语言版） <a class="header-anchor" href="#删除算法-自然语言版" aria-label="Permalink to &quot;删除算法（自然语言版）&quot;">​</a></h4><p>输入：删除区间 [l, r)。</p><ol><li>在 Pieces 上定位 l 与 r，各自落在哪些 pieces</li><li>对边界 pieces 做切分，把 [l, r) 的边界对齐到 piece 边界</li><li>删除所有完全落入 [l, r) 的 pieces</li><li>可能触发合并：相邻、同 buffer、连续 offset 的 pieces 可以合成一段（减少碎片）</li></ol><p>为了让插入/删除更“可视化”，给一个简化流程图：</p>',17)),t(l,{codeBase64:"Zmxvd2NoYXJ0IFRCCiAgSW5b6L6T5YWlOiBwb3Mg5oiWIHJhbmdlXSAtLT4gTFvlrprkvY06IOaJvuWIsOWRveS4rSBwaWVjZSDkuI7lhoXpg6jlgY/np7tdCiAgTCAtLT4gU1vliIfliIY6IOWvuem9kOi+ueeVjF0KICBTIC0tPiBNW+WPmOabtDog5o+S5YWl5pawIHBpZWNlIOaIluWIoOmZpCBwaWVjZV0KICBNIC0tPiBHW+aVtOeQhjogbWVyZ2Ug55u46YK75Y+v5ZCI5bm2IHBpZWNlc10KICBHIC0tPiBSW+a4suafky/lm57mlL46IOS7heaMiemcgCBtYXRlcmlhbGl6ZV0K"}),e[4]||(e[4]=a('<h3 id="碎片化-piece-table-的-甜点-会变成-饼干渣" tabindex="-1">碎片化：Piece Table 的“甜点”会变成“饼干渣” <a class="header-anchor" href="#碎片化-piece-table-的-甜点-会变成-饼干渣" aria-label="Permalink to &quot;碎片化：Piece Table 的“甜点”会变成“饼干渣”&quot;">​</a></h3><p>Piece Table 最大的工程副作用就是碎片化：每一次插入/删除都会切分 pieces，久而久之 pieces 会变得很碎。</p><p>碎到什么程度会出事？通常不是“用户看得出来”，而是系统会出现两类退化：</p><ul><li>定位退化：按全局位置找到命中 piece，如果你还是线性扫 pieces，会越来越慢</li><li>materialize 退化：渲染与导出时需要拼接更多片段，常数项变大，缓存命中率下降</li></ul><p>把它类比成图书馆的“目录卡片”：</p><ul><li>一开始每本书一张卡片（pieces 很少）</li><li>后来你把每一章都拆成单独卡片</li><li>再后来你把每一页也拆成单独卡片</li></ul><p>目录当然还能用，但查询与整理会越来越痛苦。</p><p>因此工程上通常会有一个明确的“整理策略”（compaction / merge），它不追求每次都最优，而追求：</p><ul><li>当碎片达到阈值时，把相邻可合并的 pieces 合并</li><li>当 addBuffer 过大或碎片过多时，做一次重写（rebuild）：把当前文档 materialize 成新 original，再清空 addBuffer</li></ul><p>一句话：Piece Table 的性能不是永远免费的，它需要你在后台做“打扫卫生”。</p><h3 id="按位置定位-为什么你迟早会把-pieces-做成树" tabindex="-1">按位置定位：为什么你迟早会把 pieces 做成树 <a class="header-anchor" href="#按位置定位-为什么你迟早会把-pieces-做成树" aria-label="Permalink to &quot;按位置定位：为什么你迟早会把 pieces 做成树&quot;">​</a></h3><p>很多人第一版都会把 pieces 存在数组里，定位靠线性扫。它确实能跑，但长文档迟早会逼你改结构。</p><p>目标很简单：把“按位置定位”从 O(#pieces) 变成 O(log #pieces)。</p><p>做法也很朴素：把 pieces 放进一棵平衡树，并在每个节点上缓存子树长度（subtreeLen）：</p><ul><li>subtreeLen(node) = subtreeLen(left) + len(piece(node)) + subtreeLen(right)</li></ul><p>这样你就可以用“走树”的方式定位位置 p：</p><ul><li>若 p &lt; subtreeLen(left)：去左子树</li><li>若 p 落在当前 piece：返回命中</li><li>否则 p := p - subtreeLen(left) - len(current)，去右子树</li></ul><p>这类结构不一定要叫 Rope，但它表达的工程意图是一样的：用树把定位成本压下去，把长文档从“偶尔卡”变成“稳定可控”。</p><h4 id="piece-table-的工程取舍-纵向深入两层" tabindex="-1">Piece Table 的工程取舍（纵向深入两层） <a class="header-anchor" href="#piece-table-的工程取舍-纵向深入两层" aria-label="Permalink to &quot;Piece Table 的工程取舍（纵向深入两层）&quot;">​</a></h4><ul><li>第一层（数据结构层）：插入/删除变成对 pieces 的 split/merge，避免复制大字符串</li><li>第二层（系统层）：undo/redo 不需要存整份文本，只需要存“结构变更（pieces 的增删改）”或“操作日志”</li></ul><p>以及它最现实的坑：</p><ul><li>碎片化：大量小插入会产生很多 piece，导致遍历、定位、渲染变慢</li><li>需要索引：findPieceAt 是线性扫，长文档会慢，需要“位置索引”（例如在树节点上缓存子树长度）</li></ul><p>这时你会走向 Rope（或者“树形 piece table”）。</p><h2 id="解决方案-2-rope-用平衡树给-piece-table-上索引" tabindex="-1">解决方案 2：Rope（用平衡树给 Piece Table 上索引） <a class="header-anchor" href="#解决方案-2-rope-用平衡树给-piece-table-上索引" aria-label="Permalink to &quot;解决方案 2：Rope（用平衡树给 Piece Table 上索引）&quot;">​</a></h2><p>Rope 的本质是：用一棵平衡树存片段，节点缓存子树长度，让“按位置定位”从 O(n) 变成 O(log n)。</p><p>现实工程里，你不一定要“标准 Rope”，只要满足两点就行：</p><ul><li>结构：树 + 可拆分/可拼接</li><li>索引：每个节点维护 <code>subtreeLength</code>，支持按位置走树</li></ul><h2 id="解决方案-3-区间树-红黑树-编辑器-range-的命脉" tabindex="-1">解决方案 3：区间树/红黑树（编辑器 range 的命脉） <a class="header-anchor" href="#解决方案-3-区间树-红黑树-编辑器-range-的命脉" aria-label="Permalink to &quot;解决方案 3：区间树/红黑树（编辑器 range 的命脉）&quot;">​</a></h2><p>编辑器里大量元信息是“区间”：</p><ul><li>高亮（syntax highlight）</li><li>批注（comment）</li><li>装饰器（decoration）</li><li>协同光标（remote cursor）</li><li>选区（selection）</li></ul><p>它们共同特征是：需要回答“某个位置/范围命中了哪些区间”。</p><p>朴素方案是线性扫：O(m)。m 一大就卡。</p><p>区间树（Interval Tree）的常见实现是：<strong>用一棵平衡 BST（例如红黑树）按 <code>start</code> 排序，每个节点维护子树 <code>maxEnd</code></strong>，从而能在 O(log m + k) 找到所有相交区间（k 是输出数量）。</p><h3 id="区间树示意图-源文件-assets-diagrams-interval-tree-mmd" tabindex="-1">区间树示意图（源文件：<code>../assets/diagrams/interval-tree.mmd</code>） <a class="header-anchor" href="#区间树示意图-源文件-assets-diagrams-interval-tree-mmd" aria-label="Permalink to &quot;区间树示意图（源文件：`../assets/diagrams/interval-tree.mmd`）&quot;">​</a></h3>',34)),t(l,{codeBase64:"Zmxvd2NoYXJ0IFRCCiAgTjFbIlsxMCwgMzBdIG1heEVuZD00MCJdIC0tPiBOMlsiWzUsIDIwXSBtYXhFbmQ9MjAiXQogIE4xIC0tPiBOM1siWzM1LCA0MF0gbWF4RW5kPTQwIl0KICBOMiAtLT4gTjRbIlsxLCA0XSBtYXhFbmQ9NCJdCiAgTjIgLS0+IE41WyJbMjEsIDIxXSBtYXhFbmQ9MjEiXQo="}),e[5]||(e[5]=a('<h3 id="区间树查询为什么能快-maxend-的剪枝逻辑-口语版" tabindex="-1">区间树查询为什么能快：maxEnd 的剪枝逻辑（口语版） <a class="header-anchor" href="#区间树查询为什么能快-maxend-的剪枝逻辑-口语版" aria-label="Permalink to &quot;区间树查询为什么能快：maxEnd 的剪枝逻辑（口语版）&quot;">​</a></h3><p>区间树节点按 start 排序，同时每个节点缓存子树的 maxEnd。查询一个范围 Q=[qₛ, qₑ] 时，你在树上做三件事：</p><ol><li>先看左子树：如果 left.maxEnd &lt; qₛ，那么左子树所有区间都结束得太早，必不相交，直接剪掉</li><li>再看当前节点：若 node.start ≤ qₑ 且 node.end ≥ qₛ，则与 Q 相交</li><li>再看右子树：如果 node.start &gt; qₑ，那么右子树 start 更大，只会更不可能相交，也可以剪掉</li></ol><p>它看起来像一堆 if，但背后是非常朴素的事实：</p><ul><li>你只要证明“这一整片子树不可能命中”，就能把线性扫描变成对数级搜索</li><li>编辑器里 ranges 动态增删，红黑树之类的平衡树确保最坏情况也不炸（这点很重要，线上事故往往来自最坏情况）</li></ul><h4 id="红黑树在这里发挥什么作用" tabindex="-1">红黑树在这里发挥什么作用？ <a class="header-anchor" href="#红黑树在这里发挥什么作用" aria-label="Permalink to &quot;红黑树在这里发挥什么作用？&quot;">​</a></h4><p>编辑器场景下，ranges 是动态的：增删频繁、数量很大、需要稳定的最坏复杂度。</p><ul><li>红黑树提供稳定的 O(log n) 插入/删除/查找（最坏也不炸）</li><li>区间树把 “maxEnd 缓存” 挂在红黑树节点上，就能把范围查询也变成可控复杂度</li></ul><p>一句话总结：红黑树不是“让你写出更帅的数据结构”，它是为了让线上性能不要因为最坏情况变成事故。</p><h2 id="工程实践-把-位置-作为第一公民-增量维护" tabindex="-1">工程实践：把“位置”作为第一公民（增量维护） <a class="header-anchor" href="#工程实践-把-位置-作为第一公民-增量维护" aria-label="Permalink to &quot;工程实践：把“位置”作为第一公民（增量维护）&quot;">​</a></h2><p>到这里，你会发现编辑器里最难的是：位置不是稳定的。</p><ul><li>文档插入一个字符后，后面的所有 range 都要平移</li><li>如果你每次都把所有区间做一次 <code>start/end</code> 加偏移，会是 O(m)</li></ul><p>解决思路通常是两条：</p><ol><li>维护映射（mapping）：把变更抽象成 step，能把旧位置映射到新位置</li><li>分段存储：range 索引按块维护，变更只影响局部块，并可延迟计算全量偏移</li></ol><h2 id="什么时候用-rope-什么时候用-piece-table-不要被名字绑架" tabindex="-1">什么时候用 Rope，什么时候用 Piece Table：不要被名字绑架 <a class="header-anchor" href="#什么时候用-rope-什么时候用-piece-table-不要被名字绑架" aria-label="Permalink to &quot;什么时候用 Rope，什么时候用 Piece Table：不要被名字绑架&quot;">​</a></h2><p>实际落地时，你经常会发现“数据结构名词”并不能直接指导工程选型，因为真正决定体验的是几件更具体的事：</p><ul><li>你的主要操作模式是什么：连续输入（小插入高频）还是大段粘贴/删除（大范围变更）</li><li>你是否需要多光标/多选区：多光标会显著放大“按位置定位”的次数</li><li>你是否需要频繁切片：例如导出、搜索、语法高亮，都在大量读取子串</li></ul><p>一个更贴地的判断标准是把成本拆开：定位成本 + 结构变更成本 + materialize 成本。</p><ul><li>如果定位是 O(#pieces) 的线性扫，#pieces 一旦增长，你会在长文档里体验到“越写越慢”</li><li>如果 materialize 每次都拼很多片段，常数项会把你拖进 GC 与缓存 miss 的泥潭</li></ul><p>所以很多工程最终会走向一种折中：前台用树索引保证定位稳定（近似 Rope 的结构），后台用 compaction 保持碎片不过度膨胀（近似 Piece Table 的工程策略）。</p><h2 id="compaction-的常见策略-打扫卫生也要讲方法" tabindex="-1">Compaction 的常见策略：打扫卫生也要讲方法 <a class="header-anchor" href="#compaction-的常见策略-打扫卫生也要讲方法" aria-label="Permalink to &quot;Compaction 的常见策略：打扫卫生也要讲方法&quot;">​</a></h2><p>整理不是越频繁越好，否则你会把本该平滑的编辑体验变成“偶尔一次大卡顿”。更常见的策略是分层触发：</p><ul><li><strong>阈值触发</strong>：当 #pieces 超过阈值，或平均片段长度低于阈值，触发一次局部合并</li><li><strong>空闲触发</strong>：在 idle/后台线程里做更重的重写（rebuild），避免抢占输入帧预算</li><li><strong>快照触发</strong>：协同/历史系统本来就需要快照窗口，重写可以顺便把“当前状态”固化为新 original</li></ul><p>你可以把一次重写理解成把“目录卡片”重新装订成一本干净的新书：它不是为了每次都最省内存，而是为了把最坏情况限制住，让系统长期运行仍然稳定。</p><h2 id="让范围索引跟得上编辑-别让-decoration-成为性能黑洞" tabindex="-1">让范围索引跟得上编辑：别让 decoration 成为性能黑洞 <a class="header-anchor" href="#让范围索引跟得上编辑-别让-decoration-成为性能黑洞" aria-label="Permalink to &quot;让范围索引跟得上编辑：别让 decoration 成为性能黑洞&quot;">​</a></h2><p>很多编辑器性能问题并不是“文本存储慢”，而是装饰器/高亮/批注这类 ranges 越积越多，最终把每次输入拖进大量区间更新与查询。你如果把范围索引当成“附加功能”，它会在长文档里变成主成本。</p><p>更稳的工程拆法是让 ranges 的维护也走“增量”：</p><ul><li>每次编辑得到一个变更 step（插入/删除/结构移动）</li><li>用 step 把旧区间映射到新区间（start/end 可能平移、收缩、或被切断）</li><li>只有映射后仍然有效的区间才继续进入索引结构</li></ul><p>这件事的意义是把“区间更新”从 O(m) 的全量平移，变成只影响局部、且可被 step 描述的变更。四舍五入：你越早把 range 索引当成一等公民，越不容易在后期被“高亮越多越卡”逼着重写。</p><h2 id="参考与引用" tabindex="-1">参考与引用 <a class="header-anchor" href="#参考与引用" aria-label="Permalink to &quot;参考与引用&quot;">​</a></h2><ol><li>ProseMirror 位置映射与 step 体系：<a href="https://prosemirror.net/docs/ref/" target="_blank" rel="noreferrer">https://prosemirror.net/docs/ref/</a> （Bib: <code>prosemirror_ref</code>）</li><li>Wikipedia: Piece table：<a href="https://en.wikipedia.org/wiki/Piece_table" target="_blank" rel="noreferrer">https://en.wikipedia.org/wiki/Piece_table</a> （Bib: <code>piece_table_wikipedia</code>）</li><li>Wikipedia: Rope (data structure)：<a href="https://en.wikipedia.org/wiki/Rope_(data_structure)" target="_blank" rel="noreferrer">https://en.wikipedia.org/wiki/Rope_(data_structure)</a> （Bib: <code>rope_wikipedia</code>）</li><li>MIT OpenCourseWare / Interval Trees（概念性资料，便于补齐 maxEnd 思路）：<a href="https://ocw.mit.edu/" target="_blank" rel="noreferrer">https://ocw.mit.edu/</a> （Bib: <code>interval_tree_mit_ocw</code>）</li></ol>',31))])}const _=o(n,[["render",c]]);export{P as __pageData,_ as default};
